## function to select best number of clusters
cluster_num =function (dataset,cluster)
{
### apply K-means from 2 to 20 clusters and build matrix of validity indeces
cluster_table1 <- data.frame(index=c('Cal','Scott','Marr','TracW','Fried'))
cluster_table2 <- data.frame(index=c('Fuz','PartDen','Xie','PartCoe'))
isCluster <- TRUE
## Index function for pam and k-means
plot_indices <- function(indexes,cluster)
{
diff_cal <- rep(NA,cluster)
diff_scott <- rep(NA,cluster)
diff_marr <- rep(NA,cluster)
diff_tracw <- rep(NA,cluster)
diff_fried <- rep(NA,cluster)
output <- list()
for (j in 2:cluster) {
diff_cal[j] <- (indexes[j+1,1]-indexes[j,1])-(indexes[j,1]-indexes[j-1,1])}
for (j in 2:cluster) {
diff_scott[j] <- (indexes[j,6]-indexes[j-1,6])}
for (j in 2:cluster) {
diff_marr[j] <- (indexes[j+1,7]-indexes[j,7])-(indexes[j,7]-indexes[j-1,7])}
for (j in 2:cluster) {
diff_tracw[j] <- (indexes[j+1,10]-indexes[j,10])-(indexes[j,10]-indexes[j-1,10])}
for (j in 2:cluster) {
diff_fried[j] <- (indexes[j,11]-indexes[j-1,11])}
output$bestCluster=c(which.min(diff_cal),which.max(diff_scott),
which.max(diff_marr),which.max(diff_tracw),which.max(diff_fried))
output$clusterRank <- matrix(data = 0, nrow = 5, ncol = cluster - 1)
for(i in 2:cluster)
{
output$clusterRank[1,i-1] <- rank(diff_cal)[i]
output$clusterRank[2,i-1] <- cluster-rank(diff_scott)[i]
output$clusterRank[3,i-1] <- cluster-rank(diff_marr)[i]
output$clusterRank[4,i-1] <- cluster-rank(diff_tracw)[i]
output$clusterRank[5,i-1] <- cluster-rank(diff_fried)[i]
}
return(output)
}
## Patch the indexes for one cluster
addClusterOne <- function(indexes,inputDataset)
{
## Calculate scott index, marriot, tracew and friedman index when cluster is 1.
rows <- nrow(inputDataset)
oneCluster <- rep(as.integer(1),time=rows)
ttww <- function(x, clsize, cluster) {
n <- sum(clsize)
k <- length(clsize)
w <- 0
tt <- cov(x) * n
for (l in 1:k) w <- w + cov(x[cluster == l, ]) * clsize[l]
zttw <- list(tt = tt, w = w)
return(zttw)
}
scott <- function(zttw, clsize) {
n <- sum(clsize)
dettt <- prod(eigen(zttw$tt)$values)
detw <- prod(eigen(zttw$w)$values)
scott <- n * log(dettt/detw)
return(scott)
}
marriot <- function(zttw, clsize) {
k <- length(clsize)
detw <- prod(eigen(zttw$w)$values)
mar <- (k^2) * detw
return(mar)
}
tracew <- function(zttw) {
tracew <- sum(diag(zttw$w))
return(tracew)
}
friedman <- function(zttw) {
b <- zttw$tt - zttw$w
fried <- sum(diag(solve(zttw$w) %*% b))
return(fried)
}
zttw<-ttww(inputDataset,rows,oneCluster)
zscott<-scott(zttw,rows)
zmarriot<-marriot(zttw,rows)
ztracew<-tracew(zttw)
zfriedman<-friedman(zttw)
## Calinski
indexes[1,1] <- 0
## scott
indexes[1,6] <- zscott
## Marriot
indexes[1,7] <- zmarriot
## TraceW
indexes[1,10] <- ztracew
## Fried
indexes[1,11] <- zfriedman
return (indexes)
}
## function to plot the fuzzy val indices
plot_indices_fcm <- function(indexes_fcm,cluster)
{
diff_fhv <- indexes_fcm[,1]
diff_pd <- indexes_fcm[,3]
diff_xb <- indexes_fcm[,4]
diff_pc <- indexes_fcm[,6]
output <- list()
output$bestCluster=c(which.min(diff_fhv),which.max(diff_pd),which.min(diff_xb),
which.max(diff_pc))
output$clusterRank <- matrix(data = 0, nrow = 4, ncol = cluster - 1)
for(i in 2:cluster)
{
output$clusterRank[1,i-1] <- rank(diff_fhv)[i]
output$clusterRank[2,i-1] <- cluster-rank(diff_pd)[i]
output$clusterRank[3,i-1] <- rank(diff_xb)[i]
output$clusterRank[4,i-1] <- cluster-rank(diff_pc)[i]
}
return(output)
}
## Calculate best Cluster number
bestCluster <- function(kmRankTable, pamRankTable, fcmRankTable, cluster)
{
finalRankTable <- rep(NA, cluster - 1)
a <- 0
b <- 0
c <- 0
for(i in 1:(cluster - 1))
{
for(l in 1:5)
{
c <- c + kmRankTable[l,i] * (3/8)
}
for(j in 1:5)
{
a <- a + pamRankTable[j,i] * (3/8)
}
for(k in 1:4)
{
b <- b + fcmRankTable[k,i] * (1/4)
}
finalRankTable[i] <- a + b + c
a <- 0
b <- 0
c <- 0
}
return(which.min(finalRankTable)+1)
}
while(isCluster){
isCluster <- FALSE
kmIndexes <- matrix(data = 0, nrow = cluster + 1, ncol = 15)
pamIndexes <- matrix(data = 0, nrow = cluster + 1, ncol = 15)
fcmIndexes <- matrix(data = NA, nrow = cluster, ncol = 9)
kmRankTable <- matrix(data = 0, nrow = 5, ncol = (cluster - 1))
pamRankTable <- matrix(data = 0, nrow = 5, ncol = (cluster -1))
fcmRankTable <- matrix(data = 0, nrow = 4, ncol = (cluster - 1))
### HCA algorithm
h <- hclust(dist(dataset), method="average")
### K-means part
for (i in 2:(cluster+1)) {
initial <- tapply(dataset, list(rep(cutree(h,i), ncol(dataset)), col(dataset)), mean)
cl <- kmeans(dataset,initial,iter)
if(suppressWarnings(min(cl$size) == 1))
{
cluster <- i - 2
isCluster <- TRUE
warning(paste("The cluster of current dataset cannot be set more than",cluster))
break
}
if("try-error" %in% class(try(suppressWarnings(clustIndex(cl,dataset,index="all")))))
{
cluster <- i - 2
if(cluster < 2)
{
stop("The indexes cannot be calculated")
}
isCluster <- TRUE
warning(paste("The cluster of current dataset cannot be set more than",cluster))
break
}
kmIndexes[i,] <- suppressWarnings(clustIndex(cl,dataset,index="all"))
}
## If cluster is reset, start another circle of this loop
if(isCluster)
{
next
}
kmIndexes <- addClusterOne(kmIndexes,dataset)
KM<-list()
KM<-plot_indices(kmIndexes,cluster)
cluster_table1<-cbind(cluster_table1,KM$bestCluster)
kmRankTable <- KM$clusterRank
miowss <- function(centri, cluster, dati) {
retval <- rep(0, nrow(centri))
x <- (dati - centri[cluster, ])^2
for (k in 1:nrow(centri)) {
retval[k] <- sum(x[cluster == k, ])
}
retval
}
## PAM algorithm
for (i in 2:(cluster + 1)) {
cl <- pam(dataset, i, diss = inherits(dataset, "dist"), metric = dist,
medoids = NULL, stand = FALSE, cluster.only = FALSE)
if(suppressWarnings(min(cl$size) == 1))
{
cluster <- i - 2
isCluster <- TRUE
warning(paste("The cluster of current dataset cannot be set more than",cluster))
break
}
cl$centers <- cl$medoids
cl$cluster <- cl$clustering
cl$size <- table(cl$cluster)[]
cl$withins <- miowss(cl$centers, cl$cluster, dataset)
if("try-error" %in% class(try(suppressWarnings(clustIndex(cl, dataset, index="all")))))
{
cluster <- i - 2
if(cluster < 2)
{
stop("The indexes cannot be calculated")
}
isCluster <- TRUE
warning(paste("The cluster of current dataset cannot be set more than",cluster))
break
}
pamIndexes[i,] <- suppressWarnings(clustIndex(cl, dataset, index="all"))
}
## If cluster is reset, start another circle of this loop
if(isCluster)
{
next
}
pamIndexes <- addClusterOne(pamIndexes,dataset)
PAM <- plot_indices(pamIndexes,cluster)
cluster_table1<-cbind(cluster_table1,PAM$bestCluster)
pamRankTable <- PAM$clusterRank
for (i in 2:cluster) {
initial <- tapply(dataset, list(rep(cutree(h,i), ncol(dataset)), col(dataset)), mean)
cl <- cmeans(dataset,initial, iter,verbose=FALSE,dist = dist, method="cmeans",m=2,initial)
if(suppressWarnings(min(cl$size) == 1 ))
{
cluster <- i - 2
isCluster <- TRUE
break
}
if("try-error" %in% class(try(suppressWarnings(fclustIndex(cl,dataset,index="all")))))
{
cluster <- i - 2
if(cluster < 2)
{
stop("The indexes cannot be calculated")
}
isCluster <- TRUE
warning(paste("The cluster of current dataset cannot be set more than",cluster))
break
}
fcmIndexes[i,] <- suppressWarnings(fclustIndex(cl,dataset,index="all"))
}
## If cluster is reset, start another circle of this loop
if(isCluster)
{
next
}
FCM <- list()
FCM<-plot_indices_fcm(fcmIndexes,cluster)
cluster_table2<-cbind(cluster_table2,FCM$bestCluster)
fcmRankTable <- FCM$clusterRank
}
clusterNum <- 0
clusterNum <- bestCluster(kmRankTable, pamRankTable, fcmRankTable,cluster)
return (clusterNum)
}
## function to generate the representing color according to the number of cluster
cluster_color <- function(cluster, final_dataset)
{
color_cluster <- list()
dataset_number <- dim(final_dataset)[1]
colors_use <- rainbow(cluster + 1)
cluster_label = rep(NA, cluster + 1)
cluster_label[1] <- "NC"
colors_output <- rep(NA, dataset_number)
pch_sty <- rep(4, dataset_number)
for(i in 1 : cluster){
cluster_label[i+1] <- i
}
for(j in 1 : dataset_number)
{
for(k in 1 : (cluster + 1))
{
if(final_dataset$class[j] == cluster_label[k])
{
colors_output[j] <- colors_use[k]
break
}
}
}
for(l in 1 : (cluster + 1))
{
cluster_label[l] <- paste("Cluster",cluster_label[l],sep=" ")
}
for(m in 2 : (cluster + 1))
{
pch_sty[m] <- 1
}
color_cluster$colors <- colors_output
color_cluster$legendName <- cluster_label
color_cluster$legendColor <- colors_use
color_cluster$legendPch <- pch_sty
return(color_cluster)
}
## find out the number of labels (clusters)
number = cluster_num(dataset, cluster)
#create the tree of the orginal tree
h <- hclust(dist(dataset), method="average")
##Kmeans
initial <- tapply(dataset, list(rep(cutree(h,number), ncol(dataset)), col(dataset)), mean)
cl_km <- kmeans(dataset,initial, iter)
km <- data.frame(dataset, clust=cl_km$cluster)
##pam
cl_pam <- pam(dataset, number, diss = inherits(dataset, "dist"), metric = dist,
medoids = NULL, stand = FALSE, cluster.only = FALSE)
pam <- data.frame(dataset, clust=cl_pam$clustering)
##FCM
initial <- tapply(dataset, list(rep(cutree(h,number), ncol(dataset)), col(dataset)), mean)
cl <- cmeans(dataset,initial,iter,verbose=FALSE,dist= dist, method="cmeans",m=2,initial)
fcm <- data.frame(dataset, clust=cl$cluster)
#construct all results together
classif <- data.frame(cbind(km$clust, pam$clust, fcm$clust))
names(classif) <- c("km", "pam", "fcm")
result <- data.frame(dataset,classif)
result = as.matrix(result)
head(result)
result
label = c(4,5,6)
label
#function to pick out rows
pick<-function(data,row,value,choose){
length = dim(data)[1]
row_length = table(data[,row] == value)[2]
col_length = length(choose)
result = matrix(nrow = row_length, ncol = col_length)
a = 1
b = 1
for(i in 1:length){
if (data[b,row] == value ){
result[a,] = data[b,choose]
a = a+1
}
b = b+1
}
head(result)
return (result)
}
#function to compare distant
dis<-function(a,b){
sqrt(sum((a-b)^2))
}
length = dim(final)[1]
wide   = dim(final)[2]
length_label = length(label)
l = length(table(final[,label[1]]))
length_attr = wide - length_label
attr = 1:length_attr
pivot = array(0,c(l,length_attr,length_label))
#calculate the centers of the first label attribute
for(w in 1:length_label){
for(u in 1:l){
pivot[u,,w] <-colMeans(pick(final,label[w],u,attr))
}
}
#initialize the rank array
coff = array(0,c(l,l,length_label-1))
final = result
#function to pick out rows
pick<-function(data,row,value,choose){
length = dim(data)[1]
row_length = table(data[,row] == value)[2]
col_length = length(choose)
result = matrix(nrow = row_length, ncol = col_length)
a = 1
b = 1
for(i in 1:length){
if (data[b,row] == value ){
result[a,] = data[b,choose]
a = a+1
}
b = b+1
}
head(result)
return (result)
}
#function to compare distant
dis<-function(a,b){
sqrt(sum((a-b)^2))
}
length = dim(final)[1]
wide   = dim(final)[2]
length_label = length(label)
l = length(table(final[,label[1]]))
length_attr = wide - length_label
attr = 1:length_attr
pivot = array(0,c(l,length_attr,length_label))
#calculate the centers of the first label attribute
for(w in 1:length_label){
for(u in 1:l){
pivot[u,,w] <-colMeans(pick(final,label[w],u,attr))
}
}
#initialize the rank array
coff = array(0,c(l,l,length_label-1))
coff
pivot
for(a in 1:(length_label-1)){
for(b in 1:l){
for(c in 1:l){
distant = dis(pivot[c,,1],pivot[b,,a+1])
coff[c,b,a] = distant
}
}
}
coff
per = permutations(n = l)
sum_row = nrow(per)
sum = rep(data = 0,sum_row)
rank = matrix(data = NA, nrow = l, ncol = l)
for(i in 1:2)
{
for(j in 1:sum_row)
{
for(a in 1:(length_label-1))
{
for(x in 1:(length_label-1))
{
sum[j] = sum[j] + coff[x,per[a,x],i]
}
}
}
rank[,i] <- t(per[which.min(sum),])
}
rank
head(final)
final1 = final
for(ccc in 1:length) {
for(aaa in 1:(length_label-1)){
final[ccc,label[1]+aaa] = rank[final[ccc,label[1]+aaa],aaa]
}
}
head(final)
final
sumarry(final)
table(final)
da
head(dataset)
plot(dataset)
kmeans
kk = kmeans(dataset,2)
kk
kk$cluster
number
h
##Kmeans
initial <- tapply(dataset, list(rep(cutree(h,number), ncol(dataset)), col(dataset)), mean)
cl_km <- kmeans(dataset,initial, iter)
km <- data.frame(dataset, clust=cl_km$cluster)
km
head(dataset)
initial <- tapply(dataset, list(rep(cutree(h,number), ncol(dataset)), col(dataset)), mean)
initial
cl_km <- kmeans(dataset,initial, iter)
km <- data.frame(dataset, clust=cl_km$cluster)
km
cl_pam <- pam(dataset, number, diss = inherits(dataset, "dist"), metric = dist,
medoids = NULL, stand = FALSE, cluster.only = FALSE)
pam <- data.frame(dataset, clust=cl_pam$clustering)
pam
pca
aa = princomp(dataset)
aa
aa[1:2,]
aa[,1]
aa
aa$scores[1,]
aa$scores[1:2,]
aa$scores[,1]
dim(dataset)
plot3d
coff
h
cutree(h,number)
hh <- hclust(dist(iris), method="average")
hh
cutree(hh,number)
cutree(hh,3)
h
cutree(h,2)
cutree(h,3)
cutree(h,2)
?hclust
library(scatterplot3d)
install.packages("scatterplot3d")
library(scatterplot3d)
scatterplot3d（dataset)
scatterplot3d（)
?scatterplot3d
scatterplot3d(dataset)
install.packages("rgl", dependencies = TRUE)
open3d()
library(rgl)
open3d()
plot3d(dataset)
library(cclass)
library(cclass)
library(cclass)
library(cclass)
install.packages("gregmisc")
?permutations
library(cclass)
library(cclass)
